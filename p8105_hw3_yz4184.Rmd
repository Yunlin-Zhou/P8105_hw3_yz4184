---
title: "p8105_hw3_yz4184"
author: "Yunlin Zhou"
date: "10/17/2021"
output: github_document
---
```{r}
library(tidyverse)
library(ggridges)
library(dplyr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1

```{r}
library(p8105.datasets)
data("instacart")
```

```{r}
# description of the dataset
str(instacart)
# there are 1,384,617 rows and 15 columns in this dataset. 4 character columns and 11 integer columns. there are key variables like aisle which is the name of aisles, and product_name which are the names of products bought from the asile.
```

```{r}
# How many aisles are there

aisles_cate = unique(instacart$aisle)
aisles_num = length(aisles_cate)
aisles_num

# 134

# Which aisles are the most items ordered from?

head(instacart %>% 
	count(aisle) %>% 
	arrange(desc(n)),1)

# fresh vegetables
```

```{r,fig.asp = 2}
# Make a plot that shows the number of items ordered in each aisle

item_asile = instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))

item_asile_10000 = item_asile %>%
  filter(n > 10000)

item_asile_plot =ggplot(item_asile_10000, aes(x = n, y = aisle))+
  geom_col()+
  labs(
    title = "Number of items ordered in each aisle",
    x = "Number of items ordered in each aisle",
    y = "Asile"
  )

ggsave("item_asile_plot.pdf")

item_asile_plot
```

```{r}
# Make a table showing the three most popular items in each of the aisles

baking_df = head(instacart%>%
filter(aisle=="baking ingredients")%>%
  group_by(aisle,product_name)%>%
  count()%>%
  arrange(desc(n)),3)

dog_df = head(instacart%>%
filter(aisle=="dog food care")%>%
  group_by(aisle,product_name)%>%
  count()%>%
  arrange(desc(n)),3)

packaged_df = head(instacart%>%
filter(aisle=="packaged vegetables fruits")%>%
  group_by(aisle,product_name)%>%
  count()%>%
  arrange(desc(n)),3)

popular_items = bind_rows(baking_df,dog_df,packaged_df)
knitr::kable(popular_items)
```

```{r}
# Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week

instacart%>%
  filter(days_since_prior_order == 0,
         product_name %in% c("Pink Lady Apples","Coffee Ice Cream"))%>%
  mutate(
    mean_hour=mean(order_hour_of_day))%>%
  select(product_name,mean_hour)%>%
  knitr::kable()
  
```


## Problem 2

```{r}
data("brfss_smart2010")
```

```{r}
# do some data cleaning

brfss_new = 
  brfss_smart2010 %>%
  janitor::clean_names() %>% 
  filter(
    topic == "Overall Health",
    response %in% 
      c("Poor","Fair","Good","Very good","Excellent"))%>%
  mutate(response = 
           factor(response,levels =
           c("Poor","Fair","Good","Very good","Excellent"),
                  ordered = TRUE))%>%
  arrange(response)

```

```{r}
# In 2002, which states were observed at 7 or more locations?

df_2002 = brfss_new%>%
  filter(year=="2002")%>%
  group_by(locationabbr)%>%
  summarise(
    location_num = n_distinct(locationdesc)
  )%>%
  filter(location_num>=7)

  knitr::kable(df_2002)

# In 2010

df_2010 = brfss_new%>%
  filter(year=="2010")%>%
 group_by(locationabbr)%>%
  summarise(
    location_num = n_distinct(locationdesc)
  )%>%
  filter(location_num>=7)

  knitr::kable(df_2010)
```


```{r,fig.asp= 1.5}
#  averages the data_value across locations within a state

brfss_new%>%
  filter(response == "Excellent")%>%
  group_by(year,locationabbr)%>%
  mutate(mean_data_value = mean(data_value))%>%
  group_by(year,locationabbr,mean_data_value)%>%
  summarize()%>%
  
  ggplot(aes(x= year,y=mean_data_value,group = locationabbr,color = locationabbr))+geom_line() + 
  labs(
    title = "Average value over time within a state",
    x = "Year",
    y = "Mean of data value"
  )
```

```{r}
# Make a two-panel plot

brfss_new %>%
  filter(year%in%c("2006","2010"),
         locationabbr == "NY")%>%
  group_by(year,response,data_value)%>%
  summarize()%>%
  ggplot(aes(x=data_value, y = response,fill = response))+geom_density_ridges(scale =0.85)+ facet_grid(. ~ year) + 
  labs(
    title = "Responses among locations in NY",
    x = "Data value",
    y = "Response"
  )


```


## Problem 3
```{r}
# Load, tidy, and otherwise wrangle the data

accel_df = read.csv("./accel_data.csv")%>%
  janitor::clean_names()%>%
  pivot_longer(activity_1:activity_1440,
    names_to = "activity_counts",
    names_prefix = "activity_")%>%
  mutate(day = factor(day),
    week_day_end =  case_when(
      day %in% c("Monday","Tuesday","Wednsday","Thursday","Friday")~ "weekday",
      day %in% c("Saturday","Sunday") ~ "weekend",
      TRUE      ~ ""
    ))
  

```

```{r}
# aggregate accross minutes to create a total activity variable for each day

each_day =accel_df%>%
  group_by(week,day)%>%
  mutate(sum = sum(value))%>%
  group_by(week,day,sum)%>%
  summarize()%>%
  pivot_wider(names_from = day,
              values_from = sum)

knitr::kable(each_day)

# the values would be smaller during the weekends
```

```{r,fig.asp=3}
# Accelerometer data allows the inspection activity over the course of the day.

accel_df%>%
  ggplot(aes(x=value,y=activity_counts, color = day))+geom_line()+
  labs(title = "24-hour activity time courses for each day",
       x = "Value",
       y = "Activity counts")+
  theme(legend.position = "right")
```

